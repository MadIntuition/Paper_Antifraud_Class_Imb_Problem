{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3408d53b-db67-4a41-8436-863c892bb49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm\n",
    "\n",
    "\n",
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "import sklearn.neural_network\n",
    "\n",
    "import base_functions as funcs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble  import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import imblearn\n",
    "from sklearn.linear_model  import LogisticRegression\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "data, labels = funcs.ReadCSV('./datasets/creditcard.csv', mark='Class')\n",
    "data = data.drop(columns=['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35455d7c-dd79-4a3b-b830-02973e209406",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_index=int(len(data)*0.8)\n",
    "##РАЗБИЕНИЕ ПО ВРЕМЕНИ\n",
    "data_train, data_test, labels_train, labels_test = (data.iloc[0:split_index], data.iloc[split_index:],\n",
    "                                                    labels.iloc[0:split_index], labels.iloc[split_index:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec2d24f0-ad5c-436d-a0b4-bd040abaa246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 417, number of negative: 227428\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7395\n",
      "[LightGBM] [Info] Number of data points in the train set: 227845, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "average_precision_score+ time:  0.8121083919175245\n",
      "roc_auc_score:  0.9847344150098735\n"
     ]
    }
   ],
   "source": [
    "## LightGBM по времени\n",
    "lgbmClassifier = lgbm.LGBMClassifier(objective='binary', n_estimators=600, metric='prc',\n",
    "                                     class_weight='balanced',#,reg_lambda=1\n",
    "                                     learning_rate=0.055,\n",
    "                                     max_depth=9,\n",
    "                                     reg_lambda=0.01)\n",
    "\n",
    "lgbmClassifier.fit(data_train , labels_train)\n",
    "\n",
    "predicts= lgbmClassifier.predict_proba(data_test )[:, 1]\n",
    " \n",
    "\n",
    "print('average_precision_score+ time: ' , average_precision_score(labels_test, predicts))\n",
    "print('roc_auc_score: ' , roc_auc_score(labels_test, predicts)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4355b470-5cae-4f4b-b0b2-3cf41fe5e14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_precision_score+ time:  0.8113981532863804\n",
      "roc_auc_score:  0.987397940947258\n"
     ]
    }
   ],
   "source": [
    "##RandomForest по времени\n",
    "\n",
    "RandomForestClassifier = RandomForestClassifier(class_weight='balanced', n_estimators=600, n_jobs=-1,max_depth=9)\n",
    "RandomForestClassifier.fit(data_train , labels_train)\n",
    "\n",
    "predicts= RandomForestClassifier.predict_proba(data_test )[:, 1]\n",
    " \n",
    "\n",
    "print('average_precision_score+ time: ' , average_precision_score(labels_test, predicts))\n",
    "print('roc_auc_score: ' , roc_auc_score(labels_test, predicts)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e42ae4f-9c95-41d6-9602-8875ed6145fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_precision_score+ time:  0.7637059726921287\n",
      "roc_auc_score:  0.986307826627056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bobor\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "## Логрег по времени\n",
    "\n",
    "LogisticRegressionClassifier =  LogisticRegression(class_weight='balanced' , max_iter=300)\n",
    "LogisticRegressionClassifier.fit(data_train , labels_train)\n",
    "\n",
    "predicts= LogisticRegressionClassifier.predict_proba(data_test )[:, 1]\n",
    " \n",
    "\n",
    "print('average_precision_score+ time: ' , average_precision_score(labels_test, predicts))\n",
    "print('roc_auc_score: ' , roc_auc_score(labels_test, predicts)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b625e16-2e9f-4f65-9731-0b6bda9a60aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_precision_score+ time:  0.7627341869920368\n",
      "roc_auc_score:  0.9634276138074898\n"
     ]
    }
   ],
   "source": [
    "## ВАЖНО: при запусках MLP результат варьируется от запуска к запуску\n",
    "## MLP по времени\n",
    "MLPClassifier=sklearn.neural_network.MLPClassifier(hidden_layer_sizes=(58),\n",
    "                                                              alpha=0.0001,\n",
    "                                                              activation='relu',\n",
    "                                                              early_stopping=True,\n",
    "                                                              )\n",
    "MLPClassifier.fit(data_train , labels_train)\n",
    "\n",
    "predicts= MLPClassifier.predict_proba(data_test )[:, 1]\n",
    " \n",
    "\n",
    "print('average_precision_score+ time: ' , average_precision_score(labels_test, predicts))\n",
    "print('roc_auc_score: ' , roc_auc_score(labels_test, predicts)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e09d2c92-e339-44dd-bcdc-a3b5ca36917b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 394, number of negative: 227451\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7395\n",
      "[LightGBM] [Info] Number of data points in the train set: 227845, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 397, number of negative: 227448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7395\n",
      "[LightGBM] [Info] Number of data points in the train set: 227845, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 413, number of negative: 227432\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7395\n",
      "[LightGBM] [Info] Number of data points in the train set: 227845, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 396, number of negative: 227449\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010889 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7395\n",
      "[LightGBM] [Info] Number of data points in the train set: 227845, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 397, number of negative: 227448\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7395\n",
      "[LightGBM] [Info] Number of data points in the train set: 227845, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "{'fit_time': array([3.21581674, 3.2583456 , 3.40182829, 3.30036616, 3.36696982]), 'score_time': array([0.30052209, 0.29832244, 0.31052685, 0.29761314, 0.32683134]), 'test_average_precision': array([0.89356428, 0.88305746, 0.8941889 , 0.89688899, 0.81908642]), 'test_roc_auc': array([0.9805054 , 0.97997932, 0.9776007 , 0.988413  , 0.98933523])}\n",
      "fit_time: 3.308665323257446\n",
      "score_time: 0.3067631721496582\n",
      "test_average_precision: 0.8773572097790311\n",
      "test_roc_auc: 0.983166731276315\n"
     ]
    }
   ],
   "source": [
    "##LightGBM 5 случайных разбиений датасета\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "scoring = [ 'average_precision','roc_auc']\n",
    "scores = cross_validate(lgbmClassifier, data, labels, cv=cv, scoring=scoring)\n",
    "print(scores)\n",
    "\n",
    "for i in scores.keys():\n",
    "    print(i+':', sum(scores[i])/ len(scores[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4edd161f-5816-4b64-982c-76846692751d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([66.918154  , 67.78796244, 69.57524133, 66.90465522, 70.07005811]), 'score_time': array([0.19364762, 0.18725729, 0.19055486, 0.2106216 , 0.19840932]), 'test_average_precision': array([0.84476218, 0.8423726 , 0.81983552, 0.84503464, 0.77418276]), 'test_roc_auc': array([0.98532733, 0.97921799, 0.99317008, 0.99173349, 0.9890237 ])}\n",
      "fit_time: 68.25121421813965\n",
      "score_time: 0.19609813690185546\n",
      "test_average_precision: 0.8252375388962327\n",
      "test_roc_auc: 0.9876945166545186\n"
     ]
    }
   ],
   "source": [
    "##RandomForestClassifier 5 случайных разбиений датасета\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "scoring = [ 'average_precision','roc_auc']\n",
    "scores = cross_validate(RandomForestClassifier, data, labels, cv=cv, scoring=scoring)\n",
    "print(scores)\n",
    "\n",
    "for i in scores.keys():\n",
    "    print(i+':', sum(scores[i])/ len(scores[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74e596ba-9fcb-47d9-9560-29f7d46ea3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bobor\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bobor\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bobor\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\bobor\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([5.34881449, 5.61427164, 5.61347604, 5.15121961, 5.40976977]), 'score_time': array([0.03120685, 0.03132915, 0.03123856, 0.03168726, 0.01560092]), 'test_average_precision': array([0.74876514, 0.77773885, 0.73146762, 0.8452822 , 0.67524442]), 'test_roc_auc': array([0.97954949, 0.97665522, 0.99229776, 0.99163531, 0.98879694])}\n",
      "fit_time: 5.42751030921936\n",
      "score_time: 0.028212547302246094\n",
      "test_average_precision: 0.7556996460320804\n",
      "test_roc_auc: 0.9857869440362599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bobor\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "##LogisticRegressionClassifier 5 случайных разбиений датасета\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "scoring = [ 'average_precision','roc_auc']\n",
    "scores = cross_validate(LogisticRegressionClassifier, data, labels, cv=cv, scoring=scoring)\n",
    "print(scores)\n",
    "\n",
    "for i in scores.keys():\n",
    "    print(i+':', sum(scores[i])/ len(scores[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68172c26-1f6b-48e0-a1f5-7f13ca9c1686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([10.55963826, 11.03337073, 10.89428663, 12.30860257,  9.32882571]), 'score_time': array([0.04640985, 0.04736948, 0.04603004, 0.04432797, 0.03451729]), 'test_average_precision': array([0.83720697, 0.83337803, 0.85126634, 0.85340804, 0.7650489 ]), 'test_roc_auc': array([0.95372238, 0.95104829, 0.94274457, 0.92772904, 0.93358446])}\n",
      "fit_time: 10.82494478225708\n",
      "score_time: 0.04373092651367187\n",
      "test_average_precision: 0.8280616541733595\n",
      "test_roc_auc: 0.9417657471679775\n"
     ]
    }
   ],
   "source": [
    "##MLPClassifier 5 случайных разбиений датасета\n",
    "##РЕЗУЛЬТАТ НА MLP стохастичен! каждый запуск уникален.\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "scoring = [ 'average_precision','roc_auc']\n",
    "scores = cross_validate(MLPClassifier, data, labels, cv=cv, scoring=scoring)\n",
    "print(scores)\n",
    "\n",
    "for i in scores.keys():\n",
    "    print(i+':', sum(scores[i])/ len(scores[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab9c08f-cf48-4b74-8d7d-8b54dd574056",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
