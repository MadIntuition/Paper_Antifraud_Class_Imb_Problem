{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f13fae7b-4bb2-4163-81c8-1c9626eaaaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import PIL.Image as Image\n",
    "import matplotlib.pylab as plt\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import datetime\n",
    "import keras\n",
    "import base_functions as funcs\n",
    "import numpy as np\n",
    "import lightgbm as lgbm\n",
    "data, labels = funcs.ReadCSV('./datasets/creditcard.csv', mark='Class')\n",
    "data = data.drop(columns=['Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd51a0be-a770-47a8-b521-634081547a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 417, number of negative: 227428\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7395\n",
      "[LightGBM] [Info] Number of data points in the train set: 227845, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "V17 \t 397\n",
      "V2 \t 424\n",
      "V9 \t 466\n",
      "V20 \t 477\n",
      "V15 \t 479\n",
      "V21 \t 489\n",
      "V19 \t 498\n",
      "V23 \t 514\n",
      "V6 \t 514\n",
      "V16 \t 516\n",
      "V27 \t 530\n",
      "V13 \t 531\n",
      "V8 \t 546\n",
      "V18 \t 557\n",
      "V5 \t 565\n",
      "V1 \t 571\n",
      "V25 \t 611\n",
      "V7 \t 618\n",
      "V10 \t 621\n",
      "V11 \t 627\n",
      "V3 \t 627\n",
      "V22 \t 636\n",
      "V24 \t 676\n",
      "V28 \t 717\n",
      "V12 \t 782\n",
      "Amount \t 793\n",
      "V26 \t 856\n",
      "V4 \t 889\n",
      "V14 \t 905\n"
     ]
    }
   ],
   "source": [
    "##Получаем значимость переменных из бустинга\n",
    "\n",
    "split_index=int(len(data)*0.8)\n",
    "\n",
    "data_train, data_test, labels_train, labels_test = (data.iloc[0:split_index], data.iloc[split_index:],\n",
    "                                                    labels.iloc[0:split_index], labels.iloc[split_index:])\n",
    "lgbmClassifier = lgbm.LGBMClassifier(objective='binary', n_estimators=600, metric='prc',\n",
    "                                     class_weight='balanced',   learning_rate=0.055   )\n",
    "\n",
    "lgbmClassifier.fit(data_train , labels_train)\n",
    "feat_imp=[]\n",
    "for i in enumerate(data.columns):\n",
    "    feat_imp.append([i[1], lgbmClassifier.feature_importances_[i[0]]])\n",
    "feat_imp.sort()\n",
    "sorted_importances=sorted(feat_imp, key=lambda feat: feat[1])#.reverse()   # sort by importance\n",
    "for i in sorted_importances:\n",
    "    print(i[0],'\\t' ,i[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49624222-a987-4a59-bec5-0d3681a0e4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##меняем порядок фич по значимости\n",
    "\n",
    "data=data.reindex(columns=['V14','V4','V26','Amount','V12','V28','V24','V22','V11','V3','V10','V7','V25','V1','V5','V18','V8','V13','V27','V16','V23','V6','V19','V21','V15','V20','V9','V2','V17' ])\n",
    "\n",
    "labels = np.array(labels)[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28ce873f-58ee-4420-8155-47aef53307db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 213605 val: 14240 test: 56962\n"
     ]
    }
   ],
   "source": [
    "##дробим на выборки по времени\n",
    "\n",
    "length=len(data)\n",
    "split_index=int(length*0.75)\n",
    "split_index_val=int(length*0.8)\n",
    "data_train, data_val, data_test, labels_train,labels_val, labels_test = \\\n",
    "    (data.iloc[0:split_index], data.iloc[split_index:split_index_val],data.iloc[split_index_val:],\n",
    "                          labels[0:split_index], labels[split_index:split_index_val], labels[split_index_val:])\n",
    "print(\"train:\", len(data_train), \"val:\", len(data_val), \"test:\", len(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "693fc0e4-2e12-49b7-945e-7e966450ea2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##стандартизируем данные\n",
    "data_train, data_test, labels_train, labels_test =train_test_split(data, labels,\n",
    "                                                                  test_size=0.2, random_state=4)\n",
    "data_val,labels_val=data_test,labels_test\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(data_train)\n",
    "data_train, data_val, data_test = scaler.transform(data_train), scaler.transform(data_val), scaler.transform(data_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd67921c-ebed-4d7e-a459-fc5ddf28299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Функции конвертации в тензор \n",
    "\n",
    "def shuffle_Vector(vector): ##функция для задания шаффла, не используется , поэтому строка шаффла закомментирована\n",
    "    copy_Vec=np.copy(vector)\n",
    "    #np.random.shuffle(np.copy(copy_Vec))\n",
    "    return copy_Vec\n",
    "\n",
    "def my_func(arg):\n",
    "    matrix = [shuffle_Vector(arg) for i in range(len(arg))]\n",
    "    matrix=arg\n",
    "    arg = tf.convert_to_tensor(np.concatenate([matrix], -1).reshape(1, 29), dtype=tf.float16)\n",
    "    return arg\n",
    "\n",
    "def convert_to_tensors(data):\n",
    "    converted_data=[]\n",
    "    counter=1\n",
    "    for i in data:\n",
    "        if counter%2000==0: print(counter)\n",
    "        counter+=1\n",
    "        converted_data.append(my_func(np.concatenate([i],axis=0)))\n",
    "    return converted_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a0feeee-cf1b-47eb-9400-9d19fa89ab06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "10000\n",
      "12000\n",
      "14000\n",
      "16000\n",
      "18000\n",
      "20000\n",
      "22000\n",
      "24000\n",
      "26000\n",
      "28000\n",
      "30000\n",
      "32000\n",
      "34000\n",
      "36000\n",
      "38000\n",
      "40000\n",
      "42000\n",
      "44000\n",
      "46000\n",
      "48000\n",
      "50000\n",
      "52000\n",
      "54000\n",
      "56000\n",
      "58000\n",
      "60000\n",
      "62000\n",
      "64000\n",
      "66000\n",
      "68000\n",
      "70000\n",
      "72000\n",
      "74000\n",
      "76000\n",
      "78000\n",
      "80000\n",
      "82000\n",
      "84000\n",
      "86000\n",
      "88000\n",
      "90000\n",
      "92000\n",
      "94000\n",
      "96000\n",
      "98000\n",
      "100000\n",
      "102000\n",
      "104000\n",
      "106000\n",
      "108000\n",
      "110000\n",
      "112000\n",
      "114000\n",
      "116000\n",
      "118000\n",
      "120000\n",
      "122000\n",
      "124000\n",
      "126000\n",
      "128000\n",
      "130000\n",
      "132000\n",
      "134000\n",
      "136000\n",
      "138000\n",
      "140000\n",
      "142000\n",
      "144000\n",
      "146000\n",
      "148000\n",
      "150000\n",
      "152000\n",
      "154000\n",
      "156000\n",
      "158000\n",
      "160000\n",
      "162000\n",
      "164000\n",
      "166000\n",
      "168000\n",
      "170000\n",
      "172000\n",
      "174000\n",
      "176000\n",
      "178000\n",
      "180000\n",
      "182000\n",
      "184000\n",
      "186000\n",
      "188000\n",
      "190000\n",
      "192000\n",
      "194000\n",
      "196000\n",
      "198000\n",
      "200000\n",
      "202000\n",
      "204000\n",
      "206000\n",
      "208000\n",
      "210000\n",
      "212000\n",
      "214000\n",
      "216000\n",
      "218000\n",
      "220000\n",
      "222000\n",
      "224000\n",
      "226000\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "10000\n",
      "12000\n",
      "14000\n",
      "16000\n",
      "18000\n",
      "20000\n",
      "22000\n",
      "24000\n",
      "26000\n",
      "28000\n",
      "30000\n",
      "32000\n",
      "34000\n",
      "36000\n",
      "38000\n",
      "40000\n",
      "42000\n",
      "44000\n",
      "46000\n",
      "48000\n",
      "50000\n",
      "52000\n",
      "54000\n",
      "56000\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "10000\n",
      "12000\n",
      "14000\n",
      "16000\n",
      "18000\n",
      "20000\n",
      "22000\n",
      "24000\n",
      "26000\n",
      "28000\n",
      "30000\n",
      "32000\n",
      "34000\n",
      "36000\n",
      "38000\n",
      "40000\n",
      "42000\n",
      "44000\n",
      "46000\n",
      "48000\n",
      "50000\n",
      "52000\n",
      "54000\n",
      "56000\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4796\\2544198262.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mconvert_to_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdata_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdata_test\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mconvert_to_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mlabels_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mlabels_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mlabels_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6289\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6290\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6291\u001b[0m         ):\n\u001b[0;32m   6292\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6293\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "\n",
    "data_train= convert_to_tensors(data_train)\n",
    "data_val = convert_to_tensors(data_val)\n",
    "data_test= convert_to_tensors(data_test)\n",
    "labels_train=labels_train.reshape(len(labels_train),1)\n",
    "labels_val=labels_val.reshape(len(labels_val),1)\n",
    "labels_test=labels_test.reshape(len(labels_test),1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4cef99b3-a4d9-4d6f-b248-a520edf6c1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##варианты смещений\n",
    "\n",
    "initial_bias = np.log([sum(labels_train)/(len(labels_train)-sum(labels_train))])\n",
    "initial_bias = tf.keras.initializers.Constant(initial_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d958553-13e1-444b-89e4-c53559b09e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##веса классов\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 classes=np.unique(labels_train), y=labels_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a85a04-660d-4d25-867a-8426a38cadcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 1, 22, 32)         288       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 1, 15, 16)         4112      \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 240)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 241       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4641 (18.13 KB)\n",
      "Trainable params: 4641 (18.13 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "WARNING:tensorflow:From C:\\Users\\bobor\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bobor\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:5818: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 11s 4ms/step - loss: 1.5324 - tp: 175.0000 - fp: 91.0000 - tn: 179608.0000 - fn: 126.0000 - accuracy: 0.9988 - precision: 0.6579 - recall: 0.5814 - auc: 0.8581 - prc: 0.5135 - val_loss: 0.5149 - val_tp: 84.0000 - val_fp: 14.0000 - val_tn: 56847.0000 - val_fn: 17.0000 - val_accuracy: 0.9995 - val_precision: 0.8571 - val_recall: 0.8317 - val_auc: 0.9686 - val_prc: 0.8316\n",
      "Epoch 2/150\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.5365 - tp: 235.0000 - fp: 41.0000 - tn: 179605.0000 - fn: 84.0000 - accuracy: 0.9993 - precision: 0.8514 - recall: 0.7367 - auc: 0.9253 - prc: 0.7620 - val_loss: 0.3736 - val_tp: 84.0000 - val_fp: 13.0000 - val_tn: 56848.0000 - val_fn: 17.0000 - val_accuracy: 0.9995 - val_precision: 0.8660 - val_recall: 0.8317 - val_auc: 0.9644 - val_prc: 0.8643\n",
      "Epoch 3/150\n",
      "2500/2500 [==============================] - 9s 3ms/step - loss: 0.4909 - tp: 234.0000 - fp: 39.0000 - tn: 179614.0000 - fn: 78.0000 - accuracy: 0.9993 - precision: 0.8571 - recall: 0.7500 - auc: 0.9254 - prc: 0.7749 - val_loss: 0.3618 - val_tp: 79.0000 - val_fp: 6.0000 - val_tn: 56855.0000 - val_fn: 22.0000 - val_accuracy: 0.9995 - val_precision: 0.9294 - val_recall: 0.7822 - val_auc: 0.9405 - val_prc: 0.8550\n",
      "Epoch 4/150\n",
      "2500/2500 [==============================] - 8s 3ms/step - loss: 0.4772 - tp: 244.0000 - fp: 31.0000 - tn: 179615.0000 - fn: 75.0000 - accuracy: 0.9994 - precision: 0.8873 - recall: 0.7649 - auc: 0.9316 - prc: 0.7880 - val_loss: 0.3673 - val_tp: 83.0000 - val_fp: 9.0000 - val_tn: 56852.0000 - val_fn: 18.0000 - val_accuracy: 0.9995 - val_precision: 0.9022 - val_recall: 0.8218 - val_auc: 0.9551 - val_prc: 0.8656\n",
      "Epoch 5/150\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 0.4190 - tp: 229.0000 - fp: 34.0000 - tn: 179667.0000 - fn: 70.0000 - accuracy: 0.9994 - precision: 0.8707 - recall: 0.7659 - auc: 0.9408 - prc: 0.8194 - val_loss: 0.3323 - val_tp: 84.0000 - val_fp: 11.0000 - val_tn: 56850.0000 - val_fn: 17.0000 - val_accuracy: 0.9995 - val_precision: 0.8842 - val_recall: 0.8317 - val_auc: 0.9648 - val_prc: 0.8797\n",
      "Epoch 6/150\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 0.4376 - tp: 227.0000 - fp: 34.0000 - tn: 179625.0000 - fn: 79.0000 - accuracy: 0.9994 - precision: 0.8697 - recall: 0.7418 - auc: 0.9339 - prc: 0.8120 - val_loss: 0.3160 - val_tp: 84.0000 - val_fp: 14.0000 - val_tn: 56847.0000 - val_fn: 17.0000 - val_accuracy: 0.9995 - val_precision: 0.8571 - val_recall: 0.8317 - val_auc: 0.9649 - val_prc: 0.8866\n",
      "Epoch 7/150\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 0.4516 - tp: 222.0000 - fp: 24.0000 - tn: 179639.0000 - fn: 80.0000 - accuracy: 0.9994 - precision: 0.9024 - recall: 0.7351 - auc: 0.9343 - prc: 0.7928 - val_loss: 0.3323 - val_tp: 84.0000 - val_fp: 13.0000 - val_tn: 56848.0000 - val_fn: 17.0000 - val_accuracy: 0.9995 - val_precision: 0.8660 - val_recall: 0.8317 - val_auc: 0.9602 - val_prc: 0.8878\n",
      "Epoch 8/150\n",
      "2500/2500 [==============================] - 9s 4ms/step - loss: 0.4389 - tp: 234.0000 - fp: 30.0000 - tn: 179621.0000 - fn: 80.0000 - accuracy: 0.9994 - precision: 0.8864 - recall: 0.7452 - auc: 0.9403 - prc: 0.8265 - val_loss: 0.2880 - val_tp: 84.0000 - val_fp: 6.0000 - val_tn: 56855.0000 - val_fn: 17.0000 - val_accuracy: 0.9996 - val_precision: 0.9333 - val_recall: 0.8317 - val_auc: 0.9650 - val_prc: 0.8929\n",
      "Epoch 9/150\n",
      "2108/2500 [========================>.....] - ETA: 1s - loss: 0.3551 - tp: 207.0000 - fp: 26.0000 - tn: 151489.0000 - fn: 54.0000 - accuracy: 0.9995 - precision: 0.8884 - recall: 0.7931 - auc: 0.9533 - prc: 0.8511"
     ]
    }
   ],
   "source": [
    "## обучение модели\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (1, 8), activation='relu', input_shape=(1,29 ,1)))\n",
    "#model.add(layers.MaxPooling2D((1, 2)))\n",
    "model.add(layers.Conv2D(16, (1, 8), activation='relu'))\n",
    "#model.add(layers.Dropout(0.05))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "                            #, bias_initializer=initial_bias\n",
    "\n",
    "print(model.summary())\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_prc',\n",
    "    verbose=1,\n",
    "    patience=6,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss_weights=class_weights,\n",
    "             # loss=tf.keras.losses.BinaryFocalCrossentropy(from_logits=True ),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[ keras.metrics.TruePositives(name='tp'),\n",
    "                                      keras.metrics.FalsePositives(name='fp'),\n",
    "                                      keras.metrics.TrueNegatives(name='tn'),\n",
    "                                      keras.metrics.FalseNegatives(name='fn'),\n",
    "                                      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "                                      keras.metrics.Precision(name='precision'),\n",
    "                                      keras.metrics.Recall(name='recall'),\n",
    "                                      keras.metrics.AUC(name='auc'),\n",
    "                                      keras.metrics.AUC(name='prc', curve='PR')\n",
    "                      ],\n",
    "               )\n",
    "\n",
    "history = model.fit(tf.stack(data_train), labels_train, epochs=150, batch_size=72,\n",
    "                    steps_per_epoch=2500,\n",
    "                    validation_data=(tf.stack(data_val), labels_val), callbacks=[early_stopping],\n",
    "                    workers=12, use_multiprocessing=True)\n",
    "\n",
    "\n",
    "\n",
    "model.save_weights('./checkpoints/my_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8949e1-1fa2-419d-a9f5-2b24bcc5a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "##графики\n",
    "from sklearn.metrics import PrecisionRecallDisplay, precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "predicts=model.predict(tf.stack(data_test))\n",
    "print(predicts)\n",
    "print('average_precision_score: ' , average_precision_score(labels_test, predicts))\n",
    "print('roc_auc_score: ' , roc_auc_score(labels_test, predicts))\n",
    "\n",
    "prec, recall, _ = precision_recall_curve(labels_test, predicts, pos_label=1)\n",
    "pr_display = PrecisionRecallDisplay(precision=prec, recall=recall).plot()\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "def plot_metrics(history):\n",
    "  metrics = ['loss', 'prc', 'precision', 'recall']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(2,2,n+1)\n",
    "    plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_'+metric],\n",
    "             color=colors[0], linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    elif metric == 'auc':\n",
    "      plt.ylim([0.8,1])\n",
    "    else:\n",
    "      plt.ylim([0,1])\n",
    "\n",
    "    plt.legend();\n",
    "\n",
    "plot_metrics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36340b67-d504-462b-ac0a-7b73f8ea205b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
